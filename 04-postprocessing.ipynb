{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing \n",
    "\n",
    "This is from the IBM360 demo, with minor modifications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of an odds-equalizing post-processing algorithm for bias mitigiation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "                import load_preproc_data_adult, load_preproc_data_compas\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness metrics for original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "\n",
    "dataset_orig = GermanDataset()\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "# try again with protections on gender\n",
    "# privileged_groups = [{'sex': 1}]\n",
    "# unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "\n",
    "\n",
    "# cost constraint of fnr will optimize generalized false negative rates, that of\n",
    "# fpr will optimize generalized false positive rates, and weighted will optimize\n",
    "# a weighted combination of both\n",
    "cost_constraint = \"fnr\" # \"fnr\", \"fpr\", \"weighted\"\n",
    "#random seed for calibrated equal odds prediction\n",
    "randseed = 12345679 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide dataset into train, validation, and test partitions (70-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.6], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Difference Metric for the original datasets (without any classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "metric_orig_valid = BinaryLabelDatasetMetric(dataset_orig_valid, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original validation dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_valid.mean_difference())\n",
    "\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original test dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try `disparate_impact`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier (logistic regression on original training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Placeholder for predicted and transformed datasets\n",
    "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "\n",
    "dataset_new_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_new_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "\n",
    "# Logistic regression classifier and predictions for training data\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "\n",
    "fav_idx = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "y_train_pred_prob = lmod.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "# Prediction probs for validation and testing data\n",
    "X_valid = scale_orig.transform(dataset_orig_valid.features)\n",
    "y_valid_pred_prob = lmod.predict_proba(X_valid)[:,fav_idx]\n",
    "\n",
    "X_test = scale_orig.transform(dataset_orig_test.features)\n",
    "y_test_pred_prob = lmod.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "class_thresh = 0.5\n",
    "dataset_orig_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_orig_valid_pred.scores = y_valid_pred_prob.reshape(-1,1)\n",
    "dataset_orig_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "y_train_pred = np.zeros_like(dataset_orig_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_orig_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_orig_train_pred.unfavorable_label\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "y_valid_pred = np.zeros_like(dataset_orig_valid_pred.labels)\n",
    "y_valid_pred[y_valid_pred_prob >= class_thresh] = dataset_orig_valid_pred.favorable_label\n",
    "y_valid_pred[~(y_valid_pred_prob >= class_thresh)] = dataset_orig_valid_pred.unfavorable_label\n",
    "dataset_orig_valid_pred.labels = y_valid_pred\n",
    "    \n",
    "y_test_pred = np.zeros_like(dataset_orig_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_orig_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_orig_test_pred.unfavorable_label\n",
    "dataset_orig_test_pred.labels = y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results before post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_pred_train = ClassificationMetric(dataset_orig_train, dataset_orig_train_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Predicted training dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_pred_train.difference(cm_pred_train.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_pred_train.difference(cm_pred_train.generalized_false_negative_rate))\n",
    "\n",
    "cm_pred_valid = ClassificationMetric(dataset_orig_valid, dataset_orig_valid_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Predicted validation dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_pred_valid.difference(cm_pred_valid.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_pred_valid.difference(cm_pred_valid.generalized_false_negative_rate))\n",
    "\n",
    "cm_pred_test = ClassificationMetric(dataset_orig_test, dataset_orig_test_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Predicted testing dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_pred_test.difference(cm_pred_test.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_pred_test.difference(cm_pred_test.generalized_false_negative_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform odds equalizing post processing on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds equalizing post-processing algorithm\n",
    "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Learn parameters to equalize odds and apply to create a new dataset\n",
    "cpp = CalibratedEqOddsPostprocessing(privileged_groups = privileged_groups,\n",
    "                                     unprivileged_groups = unprivileged_groups,\n",
    "                                     cost_constraint=cost_constraint,\n",
    "                                     seed=randseed)\n",
    "cpp = cpp.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform validation and test data using the post processing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_valid_pred = cpp.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred = cpp.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore these to see how the post processing changed the decisions before you look at the performance below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results after post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_transf_valid = ClassificationMetric(dataset_orig_valid, dataset_transf_valid_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Transformed validation dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_transf_valid.difference(cm_transf_valid.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_transf_valid.difference(cm_transf_valid.generalized_false_negative_rate))\n",
    "\n",
    "cm_transf_test = ClassificationMetric(dataset_orig_test, dataset_transf_test_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Transformed testing dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_transf_test.difference(cm_transf_test.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_transf_test.difference(cm_transf_test.generalized_false_negative_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: Check if the rates for validation data has gone down\n",
    "assert np.abs(cm_transf_valid.difference(cm_transf_valid.generalized_false_negative_rate)) < np.abs(cm_pred_valid.difference(cm_pred_valid.generalized_false_negative_rate)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above assertion confirms that there was improvement. How much improvement did it make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique optimizes the equalized odds, but not other fairness metrics.  Can you find one that it does not improve? or improves much less?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This computes for various decision thresholds, performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds\n",
    "all_thresh = np.linspace(0.01, 0.99, 25)\n",
    "display(Markdown(\"#### Classification thresholds used for validation and parameter selection\"))\n",
    "\n",
    "bef_avg_odds_diff_test = []\n",
    "bef_avg_odds_diff_valid = []\n",
    "aft_avg_odds_diff_test = []\n",
    "aft_avg_odds_diff_valid = []\n",
    "bef_bal_acc_valid = []\n",
    "bef_bal_acc_test = []\n",
    "aft_bal_acc_valid = []\n",
    "aft_bal_acc_test = []\n",
    "for thresh in tqdm(all_thresh):\n",
    "    \n",
    "    dataset_orig_valid_pred_thresh = dataset_orig_valid_pred.copy(deepcopy=True)\n",
    "    dataset_orig_test_pred_thresh = dataset_orig_test_pred.copy(deepcopy=True)\n",
    "    dataset_transf_valid_pred_thresh = dataset_transf_valid_pred.copy(deepcopy=True)\n",
    "    dataset_transf_test_pred_thresh = dataset_transf_test_pred.copy(deepcopy=True)\n",
    "    \n",
    "    # Labels for the datasets from scores\n",
    "    y_temp = np.zeros_like(dataset_orig_valid_pred_thresh.labels)\n",
    "    y_temp[dataset_orig_valid_pred_thresh.scores >= thresh] = dataset_orig_valid_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_orig_valid_pred_thresh.scores >= thresh)] = dataset_orig_valid_pred_thresh.unfavorable_label\n",
    "    dataset_orig_valid_pred_thresh.labels = y_temp\n",
    "\n",
    "    y_temp = np.zeros_like(dataset_orig_test_pred_thresh.labels)\n",
    "    y_temp[dataset_orig_test_pred_thresh.scores >= thresh] = dataset_orig_test_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_orig_test_pred_thresh.scores >= thresh)] = dataset_orig_test_pred_thresh.unfavorable_label\n",
    "    dataset_orig_test_pred_thresh.labels = y_temp\n",
    "    \n",
    "    y_temp = np.zeros_like(dataset_transf_valid_pred_thresh.labels)\n",
    "    y_temp[dataset_transf_valid_pred_thresh.scores >= thresh] = dataset_transf_valid_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_transf_valid_pred_thresh.scores >= thresh)] = dataset_transf_valid_pred_thresh.unfavorable_label\n",
    "    dataset_transf_valid_pred_thresh.labels = y_temp\n",
    "    \n",
    "    y_temp = np.zeros_like(dataset_transf_test_pred_thresh.labels)\n",
    "    y_temp[dataset_transf_test_pred_thresh.scores >= thresh] = dataset_transf_test_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_transf_test_pred_thresh.scores >= thresh)] = dataset_transf_test_pred_thresh.unfavorable_label\n",
    "    dataset_transf_test_pred_thresh.labels = y_temp\n",
    "    \n",
    "    # Metrics for original validation data\n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                                 dataset_orig_valid_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    bef_avg_odds_diff_valid.append(classified_metric_orig_valid.equal_opportunity_difference())\n",
    "\n",
    "    bef_bal_acc_valid.append(0.5*(classified_metric_orig_valid.true_positive_rate()+\n",
    "                              classified_metric_orig_valid.true_negative_rate()))\n",
    "\n",
    "    classified_metric_orig_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_orig_test_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    bef_avg_odds_diff_test.append(classified_metric_orig_test.equal_opportunity_difference())\n",
    "    bef_bal_acc_test.append(0.5*(classified_metric_orig_test.true_positive_rate()+\n",
    "                              classified_metric_orig_test.true_negative_rate()))\n",
    "\n",
    "    # Metrics for transf validing data\n",
    "    classified_metric_transf_valid = ClassificationMetric(\n",
    "                                     dataset_orig_valid, \n",
    "                                     dataset_transf_valid_pred_thresh,\n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "    aft_avg_odds_diff_valid.append(classified_metric_transf_valid.equal_opportunity_difference())\n",
    "    aft_bal_acc_valid.append(0.5*(classified_metric_transf_valid.true_positive_rate()+\n",
    "                              classified_metric_transf_valid.true_negative_rate()))\n",
    "\n",
    "    # Metrics for transf validation data\n",
    "    classified_metric_transf_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_transf_test_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    aft_avg_odds_diff_test.append(classified_metric_transf_test.equal_opportunity_difference())\n",
    "    aft_bal_acc_test.append(0.5*(classified_metric_transf_test.true_positive_rate()+\n",
    "                                  classified_metric_transf_test.true_negative_rate()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make plots that show how the accuracy and average odds changed with the post processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
